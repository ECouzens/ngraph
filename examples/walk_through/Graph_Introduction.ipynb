{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk-through\n",
    "============\n",
    "\n",
    "This walk-through guides users through several key concepts for using the nervana graph. The corresponding jupyter notebook is found [here](https://github.com/NervanaSystems/ngraph/blob/master/examples/walk_through/Graph_Introduction.ipynb).\n",
    "\n",
    "Let's begin with a very simple example: computing ``x+1`` for several values of ``x`` using the ``ngraph``\n",
    "API.  We should think of the computation as being invoked from the *host*, but possibly taking place\n",
    "somewhere else, which we will refer to as *the device.*\n",
    "\n",
    "The nervana graph currently uses a compilation model. Users first define the computations, then they are compiled and run. In the future, we plan an even more compiler-like approach, where an executable is produced that can later be run on various platforms, in addition to an interactive version.\n",
    "\n",
    "Our first program will provide values for ``x`` and receive ``x+1`` for each ``x`` provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x+1 program\n",
    "---------------\n",
    "\n",
    "The complete program, which we will walk through, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import ngraph as ng\n",
    "import ngraph.transformers as ngt\n",
    "import ngraph.transformers.passes.nviz\n",
    "\n",
    "# Build the graph\n",
    "with ng.metadata(device='numpy'):\n",
    "    x = ng.placeholder(axes=())\n",
    "x_plus_one = x + 1\n",
    "\n",
    "# Select a transformer\n",
    "transformer = ngt.make_transformer_factory('hetr')()\n",
    "transformer.register_graph_pass(ngraph.transformers.passes.nviz.VizPass(show_all_metadata=True))\n",
    "\n",
    "# Define a computation\n",
    "plus_one = transformer.computation(x_plus_one, x)\n",
    "\n",
    "# Run the computation\n",
    "for i in range(5):\n",
    "    print(plus_one(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing ``ngraph``, the Python module for graph construction, and ``ngraph.transformers``, the module for transformer operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ngraph as ng\n",
    "import ngraph.transformers as ngt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an operational graph (op-graph) for the computation.  Following TensorFlow terminology, we use ``placeholder`` to define a port for transferring tensors between the host and the device. ``Axes`` are used to tell the graph the tensor shape. In this example, ``x`` is a scalar so the axes are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = ng.placeholder(axes=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``ngraph`` graph construction API uses functions to build a graph of ``Op`` objects. Each function may add operations to the graph, and will return an ``Op`` that represents the computation. Here, the ``Op`` returned is a ``TensorOp``, which defines the Python \"magic methods\" for arithmetic (for example, ``__add__()``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_plus_one = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another bit of behind the scenes magic occurs with the Python ``1``, which is not an ``Op``. When an argument to a graph constructor is not an ``Op``, nervana graph will attempt to convert it to an ``Op`` using ``ng.constant``, the graph function for creating a constant. Thus, what is really happening is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_plus_one = ng.add(x, ng.constant(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the op-graph is defined, we can compile it with a *transformer*.  Here we use ``make_transformer`` to make a default transformer.  We tell the transformer the function to compute, ``x_plus_one``, and the associated parameter ``x``. The current default transformer uses NumPy for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select a transformer\n",
    "transformer = ngt.make_transformer()\n",
    "\n",
    "# Define a computation\n",
    "plus_one = transformer.computation(x_plus_one, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The first time the transformer executes a computation, the graph is analyzed and compiled, and storage is allocated and initialized on the device. Once compiled, the computations are callable Python objects.\n",
    "\n",
    "On each call to ``x_plus_one`` the value of ``x`` is copied to the device, 1 is added, and then the result is copied\n",
    "back from the device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the computation\n",
    "for i in range(5):\n",
    "    print(plus_one(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Compiled x + 1 Program\n",
    "The compiled code can be examined (currently located in ``/tmp`` folder) to view the runtime device model. Here we show the code with some clarifying comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self):\n",
    "        self.a_AssignableTensorOp_0_0 = None\n",
    "        self.a_AssignableTensorOp_0_0_v_AssignableTensorOp_0_0_ = None\n",
    "        self.a_AssignableTensorOp_1_0 = None\n",
    "        self.a_AssignableTensorOp_1_0_v_AssignableTensorOp_1_0_ = None\n",
    "        self.a_AddZeroDim_0_0 = None\n",
    "        self.a_AddZeroDim_0_0_v_AddZeroDim_0_0_ = None\n",
    "        self.be = NervanaObject.be\n",
    "\n",
    "    def alloc_a_AssignableTensorOp_0_0(self):\n",
    "        self.update_a_AssignableTensorOp_0_0(np.empty(1, dtype=np.dtype('float32')))\n",
    "\n",
    "    def update_a_AssignableTensorOp_0_0(self, buffer):\n",
    "        self.a_AssignableTensorOp_0_0 = buffer\n",
    "        self.a_AssignableTensorOp_0_0_v_AssignableTensorOp_0_0_ = np.ndarray(shape=(), dtype=np.float32,\n",
    "            buffer=buffer, offset=0, strides=())\n",
    "\n",
    "    def alloc_a_AssignableTensorOp_1_0(self):\n",
    "        self.update_a_AssignableTensorOp_1_0(np.empty(1, dtype=np.dtype('float32')))\n",
    "\n",
    "    def update_a_AssignableTensorOp_1_0(self, buffer):\n",
    "        self.a_AssignableTensorOp_1_0 = buffer\n",
    "        self.a_AssignableTensorOp_1_0_v_AssignableTensorOp_1_0_ = np.ndarray(shape=(), dtype=np.float32,\n",
    "            buffer=buffer, offset=0, strides=())\n",
    "\n",
    "    def alloc_a_AddZeroDim_0_0(self):\n",
    "        self.update_a_AddZeroDim_0_0(np.empty(1, dtype=np.dtype('float32')))\n",
    "\n",
    "    def update_a_AddZeroDim_0_0(self, buffer):\n",
    "        self.a_AddZeroDim_0_0 = buffer\n",
    "        self.a_AddZeroDim_0_0_v_AddZeroDim_0_0_ = np.ndarray(shape=(), dtype=np.float32,\n",
    "            buffer=buffer, offset=0, strides=())\n",
    "\n",
    "    def allocate(self):\n",
    "        self.alloc_a_AssignableTensorOp_0_0()\n",
    "        self.alloc_a_AssignableTensorOp_1_0()\n",
    "        self.alloc_a_AddZeroDim_0_0()\n",
    "\n",
    "    def Computation_0(self):\n",
    "        np.add(self.a_AssignableTensorOp_0_0_v_AssignableTensorOp_0_0_, \n",
    "               self.a_AssignableTensorOp_1_0_v_AssignableTensorOp_1_0_, \n",
    "               out=self.a_AddZeroDim_0_0_v_AddZeroDim_0_0_)\n",
    "\n",
    "    def init(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have two components: \n",
    "- storage for their elements (using the convention ``a_`` for the allocated storage of a tensor) and \n",
    "- views of that storage (denoted as ``a_...v_``).\n",
    "\n",
    "The ``alloc_`` methods allocate storage and then create the views of the storage that will be needed.  The view creation is separated from the allocation because storage may be allocated in multiple ways.\n",
    "\n",
    "Each allocated storage can also be initialized to, for example, random Gaussian variables. In this example, there are no initializations, so the method ``init``, which performs the one-time device\n",
    "initialization, is empty.  Constants, such as 1, are copied to the device as part of the allocation process.\n",
    "\n",
    "The method ``Computation_0`` handles the ``plus_one`` computation.  Clearly this is not the optimal way to add 1 to a scalar,\n",
    "so let's look at a more complex example next in the Logistic Regression walk-through."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
